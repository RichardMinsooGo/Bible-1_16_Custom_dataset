!pip install --upgrade --no-cache-dir gdown

from IPython.display import clear_output 
clear_output()

# Step 1 : Git clone Feature map

'''
# Clone from Github Repository
! git init .
! git remote add origin https://github.com/RichardMinsooGo/5_TF2_UCF101_video_classification.git
! git pull origin master
# ! git pull origin main
'''

# Mini-COCO dataset download from Auther's Github repository
import gdown
google_path = 'https://drive.google.com/uc?id='
file_id = '18I06ymkUqKwEon4Dsb8GqkJORwPZZxLd'
output_name = 'Cifar_10.zip'
gdown.download(google_path+file_id,output_name,quiet=False)
# https://drive.google.com/file/d/18I06ymkUqKwEon4Dsb8GqkJORwPZZxLd/view?usp=sharing

% rm -rf sample_data
!unzip /content/Cifar_10.zip -d /content/data
clear_output()
! rm /content/Cifar_10.zip

import os
from PIL import Image

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
import numpy as np

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


class CustomImageDataset(Dataset):
    def read_dataset(self):

        all_img_files = []
        all_labels = []

        class_names = os.walk(self.data_set_path).__next__()[1]

        for index, class_name in enumerate(class_names):
            label = index
            img_dir = os.path.join(self.data_set_path, class_name)
            img_files = os.walk(img_dir).__next__()[2]

            for img_file in img_files:
                img_file = os.path.join(img_dir, img_file)
                img = Image.open(img_file)
                if img is not None:
                    all_img_files.append(img_file)
                    all_labels.append(label)

        return all_img_files, all_labels, len(all_img_files), len(class_names)

    def __init__(self, data_set_path, transforms=None):
        self.data_set_path = data_set_path
        self.image_files_path, self.labels, self.length, self.num_classes = self.read_dataset()
        self.transforms = transforms

    def __getitem__(self, index):
        image = Image.open(self.image_files_path[index])
        image = image.convert("RGB")

        if self.transforms is not None:
            image = self.transforms(image)

        return {'image': image, 'label': self.labels[index]}

    def __len__(self):
        return self.length

EPOCHS = 3
batch_size = 128
learning_rate = 0.001

transforms_train = transforms.Compose([transforms.Resize((128, 128)),
                                       transforms.RandomRotation(10.),
                                       transforms.ToTensor()])

transforms_test = transforms.Compose([transforms.Resize((128, 128)),
                                      transforms.ToTensor()])

train_dataset = CustomImageDataset(data_set_path="./data/train", transforms=transforms_train)
test_dataset  = CustomImageDataset(data_set_path="./data/test", transforms=transforms_test)

# Data loader
train_ds = torch.utils.data.DataLoader(dataset=train_dataset,
                                       batch_size=batch_size, 
                                       shuffle=True)

test_ds = torch.utils.data.DataLoader(dataset=test_dataset,
                                      batch_size=batch_size, 
                                      shuffle=False)

if not (train_dataset.num_classes == test_dataset.num_classes):
    print("error: Numbers of class in training set and test set are not equal")
    exit()


num_classes = train_dataset.num_classes

"""    
# Alexnet works at custom mdel.
transfer_model = models.alexnet(pretrained=True, progress=True)

transfer_model = models.vgg16(pretrained=True, progress=True)
transfer_model = models.vgg19(pretrained=True, progress=True)
transfer_model = models.googlenet(pretrained=True)
transfer_model = models.resnet18(pretrained=False, progress=True)
transfer_model = models.resnet34(pretrained=True, progress=True)
transfer_model = models.resnet50(pretrained=True, progress=True)
transfer_model = models.resnet101(pretrained=True, progress=True)
transfer_model = models.resnet152(pretrained=False, progress=True)

transfer_model = models.squeezenet1_0(pretrained=True)
transfer_model = models.densenet161(pretrained=True)
transfer_model = models.shufflenet_v2_x1_0(pretrained=True)
transfer_model = models.resnext50_32x4d(pretrained=True)
transfer_model = models.wide_resnet50_2(pretrained=True)
transfer_model = models.mnasnet1_0(pretrained=True)

# Inception Input size is too small, image size is 299 or 150, it us not work at Colab env.
transfer_model = models.inception_v3(pretrained=True)

# Inception Input size is too small, it us not work at Colab env.
transfer_model = models.mobilenet_v2(pretrained=True)
"""

transfer_model =models.densenet161(pretrained=True, progress=True)
model=transfer_model.to(device)


# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

def train_step(model, item):
    model.train()
    images = item['image'].to(device)
    labels = item['label'].to(device)

    # Forward pass
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss_val = loss.item()

    # Backward and optimize
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    _, predicted = torch.max(outputs.data, 1)
    n_samples = len(labels)
    n_correct = (predicted == labels).sum().item()
    acc = 100.0 * n_correct / n_samples
    
    return loss_val, acc

def test_step(model, item):
    model.eval()
    images = item['image'].to(device)
    labels = item['label'].to(device)

    # Forward pass
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss_val = loss.item()

    _, predicted = torch.max(outputs.data, 1)
    n_samples = len(labels)
    n_correct = (predicted == labels).sum().item()
    acc = 100.0 * n_correct / n_samples
    
    return loss_val, acc

from tqdm import tqdm, tqdm_notebook, trange

for epoch in range(EPOCHS):
    
    with tqdm_notebook(total=len(train_ds), desc=f"Train Epoch {epoch+1}") as pbar:    
        train_losses = []
        train_accuracies = []
        
        for i_batch, item in enumerate(train_ds):
         
            loss_val, acc = train_step(model, item)
            
            train_losses.append(loss_val)
            train_accuracies.append(acc)
            
            pbar.update(1)
            pbar.set_postfix_str(f"Loss: {loss_val:.4f} ({np.mean(train_losses):.4f}) Acc: {acc:.3f} ({np.mean(train_accuracies):.3f})")


    # Test the model
    # In test phase, we don't need to compute gradients (for memory efficiency)
    with torch.no_grad():
        
        with tqdm_notebook(total=len(test_ds), desc=f"Test_ Epoch {epoch+1}") as pbar:    
            test_losses = []
            test_accuracies = []

            for item in test_ds:
                loss_val, acc = test_step(model, item)

                test_losses.append(loss_val)
                test_accuracies.append(acc)

                pbar.update(1)
                pbar.set_postfix_str(f"Loss: {loss_val:.4f} ({np.mean(test_losses):.4f}) Acc: {acc:.3f} ({np.mean(test_accuracies):.3f})")
            
